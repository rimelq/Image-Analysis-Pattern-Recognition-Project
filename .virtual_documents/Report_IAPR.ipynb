














!conda env create -f environment.yml
!conda activate iapr_project





!pip install -r requirements.txt





!python main.py \
  --train_imgs  dataset_project_iapr2025/train \
  --coco_json   dataset_project_iapr2025/train_coco_dataset.json \
  --output_root output \
  --run_name    ultimate_run \
  --conf_thresh_score 0.60 \
  --conf_thresh_vis   0.05 \
  --batch_size  16 \
  --epochs      300 \
  --k_folds     5 \
  --lr          0.005 \
  --step_size   80 \
  --gamma       0.1 \
  --patience    40 \
  --final_epochs 300 \
  --seed        42 \
  --test_folder dataset_project_iapr2025/test \
  --output_csv  submission_ultimate.csv \
  --label_names "Jelly White,Jelly Milk,Jelly Black,Amandina,Crème brulée,Triangolo,Tentation noir,Comtesse,Noblesse,Noir authentique,Passion au lait,Arabia,Stracciatella" \
  --conf_thresh 0.55









!python check.py check --path submission_ultimate.csv











import json
import numpy as np
import matplotlib.pyplot as plt

ANN_FILE = 'dataset_project_iapr2025/train_coco_dataset.json'

with open(ANN_FILE, 'r') as f:
    coco = json.load(f)

cats     = coco['categories']
cat_ids  = [c['id'] for c in cats]
labels   = [c['name'] for c in cats]

counts   = {cid: 0    for cid in cat_ids}
widths   = {cid: []   for cid in cat_ids}
heights  = {cid: []   for cid in cat_ids}

for ann in coco['annotations']:
    cid = ann['category_id']
    counts[cid] += 1
    w, h = ann['bbox'][2], ann['bbox'][3]
    widths[cid].append(w)
    heights[cid].append(h)

counts_list  = [counts[cid]               for cid in cat_ids]
med_widths   = [np.median(widths[cid])    for cid in cat_ids]
med_heights  = [np.median(heights[cid])   for cid in cat_ids]

order        = np.argsort(counts_list)
labels_s     = [labels[i]      for i in order]
counts_s     = [counts_list[i] for i in order]
mwidths_s    = [med_widths[i]  for i in order]
mheights_s   = [med_heights[i] for i in order]

fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 12), constrained_layout=True)

# Instance counts plot
bars = ax1.barh(labels_s, counts_s)
ax1.set_xlabel('Number of instances')
ax1.set_title('Fig. 3a - Instance Counts per Category')

# annotate each bar with its count
for bar in bars:
    width = bar.get_width()
    y     = bar.get_y() + bar.get_height() / 2
    ax1.text(
        width + max(counts_s) * 0.01, 
        y,
        f'{int(width)}',
        va='center',
        ha='left',
        fontsize=9
    )

# Median width vs. height plot
x  = np.arange(len(labels_s))
bw = 0.35
ax2.bar(x - bw/2, mwidths_s,  bw, label='Median Width')
ax2.bar(x + bw/2, mheights_s, bw, label='Median Height')
ax2.set_xticks(x)
ax2.set_xticklabels(labels_s, rotation=45, ha='right')
ax2.set_ylabel('Pixels')
ax2.set_title('Fig. 3b - Median Bounding‐Box Width & Height by Class')
ax2.legend()

plt.show()











import torch
from src.model import get_model

NUM_CLASSES = 14  # including background
model = get_model(NUM_CLASSES)
model.eval()

def count_params(module):
    return sum(p.numel() for p in module.parameters() if p.requires_grad)

# (1) ResNet-18 body 
resnet_body = model.backbone[0]
resnet_body_params = count_params(resnet_body)

# (2) 64-channel FPN
fpn = model.backbone[1]
fpn_params = count_params(fpn)

# (3) RPN 
rpn_params = count_params(model.rpn)

# (4) RoI head MLP 
roi_head_params = count_params(model.roi_heads.box_head)

# (5) Box predictor
box_predictor_params = count_params(model.roi_heads.box_predictor)

# Total
total_params = count_params(model)

# Count + percentage
def fmt(count):
    pct = count / total_params * 100
    return f"{count:,} ({pct:.1f}%)"

print(f"1) ResNet-18 body params:        {fmt(resnet_body_params)}")
print(f"2) 64-ch FPN params:             {fmt(fpn_params)}")
print(f"3) RPN params:                   {fmt(rpn_params)}")
print(f"4) RoI-head (TwoMLPHead) params: {fmt(roi_head_params)}")
print(f"5) Box predictor params:         {fmt(box_predictor_params)}")
print(f"\nTotal model parameters:         {total_params:,}")












import matplotlib.pyplot as plt

modules = [
    "Backbone (ResNet-18)", 
    "Mini-FPN", 
    "RPN (conv + cls/reg)", 
    "RoI TwoMLPHead", 
    "Box Predictor"
]
percentages = [93.2, 1.4, 0.3, 5.0, 0.1]

# Pie chart
plt.figure(figsize=(5, 6.5))
plt.pie(percentages, labels=modules, autopct='%1.1f%%', startangle=140)
plt.title("Parameter Budget Breakdown")
plt.axis('equal') 
plt.show()












import pandas as pd
from IPython.display import Markdown, display

df = pd.read_csv('train_metrics.csv')
df['fold'] = df['fold'].astype(str)

idx  = df.groupby('fold')['val_f1'].idxmax()
best = df.loc[idx].copy()

num = best[best['fold'].str.isdigit()].copy()
num['fold'] = num['fold'].astype(int)
num = num.sort_values('fold')

# Compute mean and std over the Cross validation folds
mean_f1 = num['val_f1'].mean()
std_f1  = num['val_f1'].std()

table = num[['fold','epoch','val_f1']].copy()
table.columns = ['Fold','Best epoch','Val-F1']
table['Val-F1'] = table['Val-F1'].map(lambda x: f"{x:.3f}")

# Cross validation folds
summary = pd.DataFrame([{
    'Fold':       'Mean ± SD',
    'Best epoch': '–',
    'Val-F1':     f"{mean_f1:.3f} ± {std_f1:.3f}"
}])

# Final run
final = best[best['fold'].str.lower()=='final']
if not final.empty:
    f = final.iloc[0]
    final_row = pd.DataFrame([{
        'Fold':       'Final',
        'Best epoch': int(f['epoch']),
        'Val-F1':     f"{f['val_f1']:.3f}"
    }])
else:
    final_row = pd.DataFrame([])

full_table = pd.concat([table, summary, final_row], ignore_index=True)

display(Markdown(full_table.to_markdown(index=False)))









import os
import torch
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
from torchvision.datasets import CocoDetection
from src.model import get_model
from src.utils import load_model, get_transform

MODEL_PATH = 'best_full.pth'
IMG_FOLDER = 'dataset_project_iapr2025/train'           
ANN_FILE   = 'dataset_project_iapr2025/train_coco_dataset.json'
CONF_THRESH= 0.0    # to collect all predictions

internal = [
    "Amandina","Arabia","Comtesse","Creme_brulee","Jelly_Black",
    "Jelly_Milk","Jelly_White","Noblesse","Noir_authentique",
    "Passion_au_lait","Stracciatella","Tentation_noir","Triangolo"
]

device    = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model     = get_model(len(internal)+1)
model     = load_model(model, MODEL_PATH, device)
model.eval()
transform = get_transform(train=False)

coco_ds = CocoDetection(root=IMG_FOLDER, annFile=ANN_FILE, transform=None)
coco    = coco_ds.coco

# collect confidences
confs = {cls: [] for cls in internal}

for img_info in coco.loadImgs(coco.getImgIds()):
    fname = img_info['file_name']
    path  = os.path.join(IMG_FOLDER, fname)

    if not os.path.isfile(path):
        base, ext = os.path.splitext(path)
        alt = base + ext.upper()
        if os.path.isfile(alt):
            path = alt
        else:
            continue

    img = Image.open(path).convert('RGB')
    img_t, _ = transform(img, {})   
    img_t = img_t.to(device)

    with torch.no_grad():
        out = model([img_t])[0]

    scores = out['scores'].cpu().numpy()
    labels = out['labels'].cpu().numpy() - 1

    for lbl, score in zip(labels, scores):
        confs[internal[lbl]].append(float(score))

# plot histograms
n    = len(internal)
cols = 4
rows = int(np.ceil(n/cols))
fig, axes = plt.subplots(rows, cols, figsize=(4*cols, 3*rows))
axes = axes.flatten()

for i, cls in enumerate(internal):
    ax = axes[i]
    data = confs[cls]
    if data:
        ax.hist(data, bins=20, range=(0,1))
    ax.set_title(f"{cls} (n={len(data)})")
    ax.set_xlim(0,1)

for j in range(n, len(axes)):
    fig.delaxes(axes[j])

fig.suptitle('Fig. 5.5 - Prediction‐Confidence Distributions by Class', y=1.02)
plt.tight_layout()
plt.show()









# Build per‐class summary DataFrame 
import json
import numpy as np
import pandas as pd
import os
import torch
from PIL import Image
from torchvision.datasets import CocoDetection
from src.model import get_model
from src.utils import load_model, get_transform

ANN_FILE   = 'dataset_project_iapr2025/train_coco_dataset.json'
IMG_FOLDER = 'dataset_project_iapr2025/train'
MODEL_PATH = 'best_full.pth'
internal   = [
    "Amandina","Arabia","Comtesse","Creme_brulee","Jelly_Black",
    "Jelly_Milk","Jelly_White","Noblesse","Noir_authentique",
    "Passion_au_lait","Stracciatella","Tentation_noir","Triangolo"
]

# Load Coco Json file for counts & box sizes
with open(ANN_FILE,'r') as f:
    coco = json.load(f)
cats     = coco['categories']
cat_ids  = [c['id'] for c in cats]
labels   = [c['name'] for c in cats]

counts   = {cid: 0    for cid in cat_ids}
widths   = {cid: []   for cid in cat_ids}
heights  = {cid: []   for cid in cat_ids}

for ann in coco['annotations']:
    cid = ann['category_id']
    counts[cid] += 1
    w,h = ann['bbox'][2], ann['bbox'][3]
    widths[cid].append(w)
    heights[cid].append(h)

# Load model & collect confidences
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model  = get_model(len(internal)+1)
model  = load_model(model, MODEL_PATH, device)
model.eval()
transform = get_transform(train=False)

ds   = CocoDetection(root=IMG_FOLDER, annFile=ANN_FILE, transform=None)
coco_api = ds.coco

confs = {cls: [] for cls in internal}
for img_info in coco_api.loadImgs(coco_api.getImgIds()):
    fname = img_info['file_name']
    path  = os.path.join(IMG_FOLDER, fname)
    
    if not os.path.isfile(path):
        base, ext = os.path.splitext(path)
        alt = base + ext.upper()
        if os.path.isfile(alt):
            path = alt
        else:
            continue

    img = Image.open(path).convert('RGB')
    img_t,_ = transform(img, {})
    img_t = img_t.to(device)
    with torch.no_grad():
        out = model([img_t])[0]
    scores = out['scores'].cpu().numpy()
    labels_pred = out['labels'].cpu().numpy() - 1
    for lbl, sc in zip(labels_pred, scores):
        confs[internal[lbl]].append(float(sc))

rows = []
for cid,name in zip(cat_ids, labels):
    med_w = np.median(widths[cid])
    med_h = np.median(heights[cid])
    mean_c = np.mean(confs[name]) if len(confs[name]) else np.nan
    std_c  = np.std(confs[name])  if len(confs[name]) else np.nan
    rows.append({
        'class': name,
        'count': counts[cid],
        'median_width': med_w,
        'median_height': med_h,
        'mean_conf': mean_c,
        'std_conf': std_c
    })

df = pd.DataFrame(rows).set_index('class')
display(df)



# Compute and print correlation matrix 
from scipy.stats import pearsonr

features = ['count','median_width','median_height','mean_conf']
print("Pairwise Pearson r:")
for i,fi in enumerate(features):
    for fj in features[i+1:]:
        xi = df[fi].values
        xj = df[fj].values
        # drop any NaNs
        mask = ~np.isnan(xi) & ~np.isnan(xj)
        r, p = pearsonr(xi[mask], xj[mask])
        print(f"  {fi:14s} vs {fj:14s}: r = {r:.3f}, p = {p:.3g}")
        
print("\nFull feature correlation matrix:")
display(df[features].corr())



# Scatter‐plots with linear fits 
import numpy as np
import matplotlib.pyplot as plt

def scatter_with_fit(x, y, ax, xlabel, ylabel):
    ax.scatter(x, y)
    # fit line
    m,b = np.polyfit(x, y, 1)
    xs = np.array([x.min(), x.max()])
    ax.plot(xs, m*xs+b, linestyle='--')
    ax.set_xlabel(xlabel)
    ax.set_ylabel(ylabel)

fig, axes = plt.subplots(1, 3, figsize=(18,5), tight_layout=True)
scatter_with_fit(df['count'],         df['mean_conf'], axes[0], 'Instance Count',       'Mean Confidence')
scatter_with_fit(df['median_width'],  df['mean_conf'], axes[1], 'Median Box Width (px)', 'Mean Confidence')
scatter_with_fit(df['median_height'], df['mean_conf'], axes[2], 'Median Box Height (px)','Mean Confidence')

fig.suptitle("Per‐class correlations with Mean Prediction Confidence", y=1.02)
plt.show()





















import pandas as pd
import matplotlib.pyplot as plt

df = pd.read_csv('train_metrics.csv')

metrics = {
    'total': 'Train Loss',
    'val_f1': 'Validation F1',
    'cls': 'Classification Loss',
    'box': 'Box Loss',
    'avg_batch_iou': 'Average Batch IoU'
}

df['fold'] = df['fold'].astype(str)

non_final_folds = sorted(
    [f for f in df['fold'].unique() if f.lower() != 'final'],
    key=lambda x: int(x)
)
has_final = any(f.lower() == 'final' for f in df['fold'].unique())

tab10        = plt.cm.tab10.colors
other_colors = [c for idx, c in enumerate(tab10) if idx != 3]

letters = ['a','b','c','d','e']

for idx, (metric_col, plot_title) in enumerate(metrics.items()):
    plt.figure(figsize=(8, 5))
    
    # Plotting each non-final fold
    for i, fold in enumerate(non_final_folds):
        d = df[df['fold'] == fold]
        plt.plot(
            d['epoch'], d[metric_col],
            label=f'Fold {fold}',
            color=other_colors[i % len(other_colors)],
            linestyle='-'
        )
    
    # Plotting the final fold in red
    if has_final:
        d_final = df[df['fold'].str.lower() == 'final']
        plt.plot(
            d_final['epoch'], d_final[metric_col],
            label='Final',
            color='red',
            linestyle='-',
            linewidth=1.25
        )

    prefix = f'Figure 6-{letters[idx]}:'
    plt.title(f'{prefix} {plot_title} vs. Epoch')
    plt.xlabel('Epoch')
    plt.ylabel(plot_title)
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()





# ──────────────────────────────────────────────────────────────────────────────
# 2) Quantitative & qualitative analysis from best_full.pth checkpoint
# ──────────────────────────────────────────────────────────────────────────────

import os
import numpy as np
import torch
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt

from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score, davies_bouldin_score
from sklearn.metrics import multilabel_confusion_matrix
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE

from src.model import get_model
from src.utils import load_model, compute_counts_from_preds, image_f1, collate_fn, get_transform
from src.dataset import ChocolateCocoDataset

DEVICE       = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
CHECKPOINT   = "best_full.pth"
IMG_FOLDER   = "dataset_project_iapr2025/train"
COCO_JSON    = "dataset_project_iapr2025/train_coco_dataset.json"
CONF_THRESH  = 0.60
BATCH_SIZE   = 4

# ─── LOAD DATASET & MODEL ────────────────────────────────────────────────────
full_val_ds = ChocolateCocoDataset(IMG_FOLDER, COCO_JSON, transforms=get_transform(train=False))
val_loader  = DataLoader(full_val_ds, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)

labels = full_val_ds.labels    
C      = len(labels)           

model = get_model(num_classes=C+1)
model = load_model(model, CHECKPOINT, DEVICE)
model.eval()

# ─── RUN INFERENCE & COLLECT COUNTS ───────────────────────────────────────────
all_true = []
all_pred = []
all_f1   = []

for imgs, targets in val_loader:
    imgs = [img.to(DEVICE) for img in imgs]

    # true counts
    for t in targets:
        y_true = np.bincount(t["labels"].numpy(), minlength=C+1)[1:]
        all_true.append(y_true)

    # model predictions
    with torch.no_grad():
        outs = model(imgs)
    for out in outs:
        y_pred = compute_counts_from_preds(out, CONF_THRESH, num_classes=C)
        all_pred.append(y_pred)

    # per‐image F1
    for yt, yp in zip(all_true[-len(outs):], all_pred[-len(outs):]):
        all_f1.append(image_f1(yt, yp))

all_true = np.vstack(all_true)   
all_pred = np.vstack(all_pred)   

print(f"\n\nAverage image‐wise F1: {np.mean(all_f1):.4f}\n")

# ─── PER‐CLASS TP/FP/FN, PRECISION/RECALL/F1 ─────────────────────────────────
TP = np.minimum(all_true, all_pred).sum(axis=0)
FP = (all_pred - np.minimum(all_true, all_pred)).sum(axis=0)
FN = (all_true - np.minimum(all_true, all_pred)).sum(axis=0)

precision = TP / (TP + FP + 1e-9)
recall    = TP / (TP + FN + 1e-9)
f1_score  = 2 * precision * recall / (precision + recall + 1e-9)

df = pd.DataFrame({
    "class":     labels,
    "TP":        TP.astype(int),
    "FP":        FP.astype(int),
    "FN":        FN.astype(int),
    "precision": precision,
    "recall":    recall,
    "f1":        f1_score
})
display(df.set_index("class"))

# ─── CLUSTERING METRICS ON IMAGE‐COUNT VECTORS ───────────────────────────────
kmeans = KMeans(n_clusters=3, random_state=0).fit(all_pred)
clusters = kmeans.labels_
sil = silhouette_score(all_pred, clusters)
db  = davies_bouldin_score(all_pred, clusters)

print("Clustering Metrics----------")
print(f"\nSilhouette Score:     {sil:.4f}")
print(f"Davies–Bouldin Index:  {db:.4f}\n")

# PCA
pca = PCA(n_components=2, random_state=0).fit_transform(all_pred)
plt.figure(figsize=(5,5))
plt.scatter(pca[:,0], pca[:,1], c=clusters, cmap='tab10', s=10)
plt.title("Fig. 6-f - PCA of count‐vectors"); plt.xlabel("PC1"); plt.ylabel("PC2"); plt.show()

# t-SNE
tsne = TSNE(n_components=2, random_state=0, init='pca').fit_transform(all_pred)
plt.figure(figsize=(5,5))
plt.scatter(tsne[:,0], tsne[:,1], c=clusters, cmap='tab10', s=10)
plt.title("Fig. 6-g - t-SNE of count‐vectors"); plt.xlabel("Dim1"); plt.ylabel("Dim2"); plt.show()

# ─── FIRST‐LAYER FILTER VISUALIZATION ────────────────────────────────────────
sd = model.state_dict()
w = sd[[k for k in sd if "conv1.weight" in k][0]].cpu()  
Nf = w.shape[0]
rows = int(np.ceil(np.sqrt(Nf)))
fig, axs = plt.subplots(rows, rows, figsize=(rows, rows))
for i, ax in enumerate(axs.flatten()):
    if i < Nf:
        filt = w[i]; filt = (filt - filt.min())/(filt.max()-filt.min())
        ax.imshow(filt.permute(1,2,0))
    ax.axis('off')
plt.suptitle("Fig. 6-h - Conv1 learned filters")
plt.tight_layout()
plt.show()

# ──── CONFUSION MATRIX ───────────────────────────────────────────────────────

y_true_bin = (all_true > 0).astype(int)
y_pred_bin = (all_pred > 0).astype(int)

mcms = multilabel_confusion_matrix(y_true_bin, y_pred_bin)

# Plot each per‐class confusion matrix heatmap
n_classes = len(labels)
cols = 3
rows = int(np.ceil(n_classes/cols))
fig, axes = plt.subplots(rows, cols, figsize=(4*cols, 4*rows))
for i, (cm, cls_name) in enumerate(zip(mcms, labels)):
    ax = axes.flat[i]
    im = ax.imshow(cm, cmap='Blues', interpolation='nearest')
    ax.set_title(cls_name, pad=10)
    ax.set_xticks([0,1]); ax.set_xticklabels(['Pred 0','Pred 1'])
    ax.set_yticks([0,1]); ax.set_yticklabels(['True 0','True 1'])

    for (r,c), v in np.ndenumerate(cm):
        ax.text(c, r, v, ha='center', va='center', color='white' if v>cm.max()/2 else 'black')

for j in range(n_classes, rows*cols):
    axes.flat[j].axis('off')
fig.suptitle("Fig. 6-i - Per‐Class Presence Confusion Matrices", y=1.02)
fig.tight_layout()
plt.show()


# ─── HEATMAP OF PRECISON / RECALL / F1 per class ────────────────────────────
met = df[['precision','recall','f1']].values

fig, ax = plt.subplots(figsize=(6, n_classes*0.4))
im = ax.imshow(met, aspect='auto', cmap='viridis')
ax.set_yticks(np.arange(n_classes))
ax.set_yticklabels(labels)
ax.set_xticks([0,1,2])
ax.set_xticklabels(['Precision','Recall','F1'])
# annotate
for i in range(n_classes):
    for j in range(3):
        ax.text(j, i, f"{met[i,j]:.2f}",
                ha='center', va='center',
                color='white' if met[i,j] > met.max()/2 else 'black')
fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)
ax.set_title("Fig. 6-j - Per‐Class Precision / Recall / F1")
plt.tight_layout()
plt.show()















import os
import random
import unicodedata
import torch
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
from matplotlib.patches import Rectangle

from src.model import get_model
from src.utils import load_model, get_transform

CHECKPOINT  = "best_full.pth"
TEST_FOLDER = "dataset_project_iapr2025/test"
CONF_THRESH = 0.55  # just like our best public leaderboard Kaggle submission
NUM_TOTAL   = 6   # total images to display (including forced)

INTERNAL = [
    "Amandina","Arabia","Comtesse","Creme_brulee","Jelly_Black",
    "Jelly_Milk","Jelly_White","Noblesse","Noir_authentique",
    "Passion_au_lait","Stracciatella","Tentation_noir","Triangolo"
]
SUBMISSION = [
    "Jelly White","Jelly Milk","Jelly Black","Amandina","Crème brulée",
    "Triangolo","Tentation noir","Comtesse","Noblesse","Noir authentique",
    "Passion au lait","Arabia","Stracciatella"
]

# Example to include forced specific test image ID's (image IDs without 'L' prefix) 
forced_ids = [
    1000762]

device    = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model     = get_model(len(INTERNAL)+1)
model     = load_model(model, CHECKPOINT, device)
model.eval()
transform = get_transform(train=False)

# label normalization
def normalize(name):
    s = unicodedata.normalize("NFKD", name)
    return s.encode("ascii","ignore").decode("ascii").replace(" ", "_")

idx_map = [ INTERNAL.index(normalize(n)) for n in SUBMISSION ]

# color mapping per class
cmap = plt.cm.get_cmap("tab20", len(SUBMISSION))
class_colors = {cls: cmap(i) for i, cls in enumerate(SUBMISSION)}

def draw_box(ax, box, label, score, color):
    x1, y1, x2, y2 = box
    ax.add_patch(Rectangle((x1, y1), x2 - x1, y2 - y1,
                           edgecolor=color, fill=False, lw=2))
    ax.text(x1, y1, f"{label} {score:.2f}",
            color="white", backgroundcolor=color, fontsize=8)

all_files = [
    f for f in os.listdir(TEST_FOLDER)
    if f.lower().endswith(('.JPG','.jpg','.jpeg','.png'))
]

forced_files = []
for tid in forced_ids:
    prefix = f"L{tid}"
    matches = [f for f in all_files if f.startswith(prefix)]
    if matches:
        forced_files.extend(matches)
    else:
        print(f"No file found for ID {tid}")

remaining = [f for f in all_files if f not in forced_files]
random.seed(42)  # to obtain the same random images that are mentioned in our analysis
random_sel = random.sample(remaining, max(0, NUM_TOTAL - len(forced_files)))
files_to_show = forced_files + random_sel

# Letters for figure labels
letters = list("abcdefghijklmnopqrstuvwxyz")

# Visualize
for idx, fname in enumerate(files_to_show):
    path = os.path.join(TEST_FOLDER, fname)
    img_pil = Image.open(path).convert("RGB")
    img_t, _ = transform(img_pil, {})
    img_np = img_t.permute(1,2,0).cpu().numpy()
    img_t = img_t.to(device)

    # Inference
    with torch.no_grad():
        preds = model([img_t])[0]

    boxes  = preds["boxes"].cpu().numpy()
    labels = preds["labels"].cpu().numpy()
    scores = preds["scores"].cpu().numpy()

    # Print counts
    keep = scores >= CONF_THRESH
    kept = labels[keep]
    counts_int = np.bincount(kept, minlength=len(INTERNAL)+1)[1:]
    counts_sub = [int(counts_int[i]) for i in idx_map]
    print(f"{fname} →", dict(zip(SUBMISSION, counts_sub)))

    # Plot 
    fig, ax = plt.subplots(figsize=(6,6))
    ax.imshow(img_np)
    ax.axis("off")
    fig_label = f"Figure 7-{letters[idx]}: {fname}"
    ax.set_title(fig_label)

    for box, lbl, score in zip(boxes, labels, scores):
        if score < CONF_THRESH:
            continue
        sub_idx = idx_map.index(lbl - 1)
        cls_name = SUBMISSION[sub_idx]
        draw_box(ax, box, cls_name, score, class_colors[cls_name])

    plt.tight_layout()
    plt.show()













